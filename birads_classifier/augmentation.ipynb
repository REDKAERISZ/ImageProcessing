{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A notebook for aumentating image datasets so small they'd fit in a toaster\n",
    "This is for cropping a Region Of Interest (ROI) but can be modified to fit full image datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydicom\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_to_3_channel(image_path, desired_range=(0, 255)):\n",
    "    dcm = pydicom.dcmread(image_path)\n",
    "    phin = dcm.get(\"PhotometricInterpretation\", \"Unknown\")\n",
    "    pixel_data = dcm.pixel_array\n",
    "\n",
    "    if phin == \"MONOCHROME2\":\n",
    "        min_value = np.min(pixel_data)\n",
    "        max_value = np.max(pixel_data)\n",
    "        pixel_data = ((pixel_data - min_value) / (max_value - min_value)) * (desired_range[1] - desired_range[0]) + desired_range[0]\n",
    "    else:\n",
    "        pixel_data = np.max(pixel_data) - pixel_data  # Invert pixel values for MONOCHROME1\n",
    "        min_value = np.min(pixel_data)\n",
    "        max_value = np.max(pixel_data)\n",
    "        pixel_data = ((pixel_data - min_value) / (max_value - min_value)) * (desired_range[1] - desired_range[0]) + desired_range[0]\n",
    "\n",
    "    if pixel_data.dtype != np.uint8:\n",
    "        pixel_data = pixel_data.astype(np.uint8)\n",
    " \n",
    "    # If grayscale, replicate into 3 channels\n",
    "    if len(pixel_data.shape) == 2:\n",
    "        pixel_data = np.stack((pixel_data,) * 3, axis=-1)\n",
    "\n",
    "    image = Image.fromarray(pixel_data)\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nxy (xmin, ymin, xmax, ymax, height, width, diff):\n",
    "\n",
    "    if (xmin - (diff/2)) >= 0 and (ymin - (diff/2)) >= 0:\n",
    "        if height > width:\n",
    "            xmin = round (xmin - (diff/2))\n",
    "            xmax = round (xmax + (diff/2)) \n",
    "        else:\n",
    "            ymin = round (ymin - (diff/2))\n",
    "            ymax = round (ymax + (diff/2))\n",
    "\n",
    "    return (xmin,ymin, xmax, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zeros (roi, height, width):\n",
    "    max_dim = max(height, width)\n",
    "    roi_image = Image.fromarray(roi) # convertir de np array a PIL\n",
    "    pad = Image.new('RGB', (max_dim, max_dim), (0, 0, 0))\n",
    "    offset = ((max_dim - roi_image.size[0]) // 2, (max_dim - roi_image.size[1]) // 2)\n",
    "    pad.paste(roi_image, offset)\n",
    "    square_roi = np.array(pad) # Convertir de PIL a np array\n",
    "    return (square_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlm_filter(roi):\n",
    "    roi_uint8 = roi.astype(np.uint8)\n",
    "    denoised_roi = cv2.fastNlMeansDenoising(roi_uint8, None, h=4)\n",
    "    return denoised_roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the transformations applied. Test with an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Image.dicom\"\n",
    "xmin = 2058\n",
    "ymin = 1648\n",
    "xmax = 2470\n",
    "ymax = 2037\n",
    "\n",
    "image = dicom_to_3_channel(path)\n",
    "roi = image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "roi_image = Image.fromarray(roi)\n",
    "\n",
    "hflip = roi_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "vflip = roi_image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "hflip = np.array(hflip)\n",
    "vflip = np.array(vflip)\n",
    "\n",
    "nlmroi = nlm_filter(roi)\n",
    "\n",
    "roi = roi.astype(float)\n",
    "min_val = np.min(roi)\n",
    "max_val =np.max(roi)\n",
    "roi = 255 * ((roi - min_val) / (max_val - min_val))\n",
    "froi = roi.astype(np.uint8)\n",
    "\n",
    "hflip = hflip.astype(float)\n",
    "min_val = np.min(hflip)\n",
    "max_val =np.max(hflip)\n",
    "hflip = 255 * ((hflip - min_val) / (max_val - min_val))\n",
    "fhflip = hflip.astype(np.uint8)\n",
    "\n",
    "vflip = vflip.astype(float)\n",
    "min_val = np.min(vflip)\n",
    "max_val =np.max(vflip)\n",
    "vflip = 255 * ((vflip - min_val) / (max_val - min_val))\n",
    "fvflip = vflip.astype(np.uint8)\n",
    "\n",
    "nlmroi = nlmroi.astype(float)\n",
    "min_val = np.min(nlmroi)\n",
    "max_val =np.max(nlmroi)\n",
    "nlmroi = 255 * ((nlmroi - min_val) / (max_val - min_val))\n",
    "fnlmroi = nlmroi.astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=[20, 7])\n",
    "plt.subplot(141); plt.imshow(froi, cmap='gray'); plt.title('OG'); plt.axis('off')\n",
    "plt.subplot(142); plt.imshow(fhflip, cmap='gray'); plt.title('hflip'); plt.axis('off')\n",
    "plt.subplot(143); plt.imshow(fvflip, cmap='gray'); plt.title('vflip'); plt.axis('off')\n",
    "plt.subplot(144); plt.imshow(fnlmroi, cmap='gray'); plt.title('NLM'); plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation (file, preproc_dir):\n",
    "    class_assessment_to_folder = {\n",
    "    ('Architectural distortion', 2): 'ArchDis_BR2',\n",
    "    ('Architectural distortion', 3): 'ArchDis_BR3',\n",
    "    ('Architectural distortion', 4): 'ArchDis_BR4',\n",
    "    ('Architectural distortion', 5): 'ArchDis_BR5',\n",
    "    ('Calcification', 2): 'Calcification_BR2',\n",
    "    ('Calcification', 3): 'Calcification_BR3',\n",
    "    ('Calcification', 4): 'Calcification_BR4',\n",
    "    ('Calcification', 5): 'Calcification_BR5',\n",
    "    ('Mass', 2): 'Mass_BR2',\n",
    "    ('Mass', 3): 'Mass_BR3',\n",
    "    ('Mass', 4): 'Mass_BR4',\n",
    "    ('Mass', 5): 'Mass_BR5',\n",
    "}\n",
    "    \n",
    "    df = pd.read_excel (file)\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        assessment = row['birads']\n",
    "        name = row['CropFileName']\n",
    "        img_class = row ['AbnormalityType']\n",
    "        image_path = row['imagePath']\n",
    "        index = round(row['Index'])\n",
    "        xmin = round(row['xmin'])\n",
    "        ymin = round(row['ymin'])\n",
    "        xmax = round(row['xmax'])\n",
    "        ymax = round(row['ymax'])\n",
    "        height = round(row['h'])\n",
    "        width = round(row['w'])\n",
    "        diff = abs (height-width)\n",
    "        \n",
    "        if image_path.endswith ('.dcm') or image_path.endswith ('.dicom') or image_path.endswith ('.DCM'): \n",
    "            image = dicom_to_3_channel(image_path)\n",
    "        elif image_path.endswith ('.pgm'):\n",
    "            image = cv2.imread(image_path, -1)\n",
    "        else:\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "        if (xmin - (diff/2)) >= 0 and (ymin - (diff/2)) >= 0:\n",
    "            xmin, ymin, xmax, ymax = find_nxy(xmin, ymin, xmax, ymax, height, width, diff)\n",
    "            \n",
    "        roi = image[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "\n",
    "        if width != height:\n",
    "            roi = add_zeros(roi, height, width)\n",
    "            \n",
    "        roi_image = Image.fromarray(roi)\n",
    "\n",
    "        hflip = roi_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        vflip = roi_image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        hflip = np.array(hflip)\n",
    "        vflip = np.array(vflip)\n",
    "\n",
    "        nlmroi = nlm_filter(roi)\n",
    "        \n",
    "        roi = roi.astype(float)\n",
    "        min_val = np.min(roi)\n",
    "        max_val =np.max(roi)\n",
    "        roi = 255 * ((roi - min_val) / (max_val - min_val))\n",
    "        froi = roi.astype(np.uint8)\n",
    "\n",
    "        hflip = hflip.astype(float)\n",
    "        min_val = np.min(hflip)\n",
    "        max_val =np.max(hflip)\n",
    "        hflip = 255 * ((hflip - min_val) / (max_val - min_val))\n",
    "        fhflip = hflip.astype(np.uint8)\n",
    "\n",
    "        vflip = vflip.astype(float)\n",
    "        min_val = np.min(vflip)\n",
    "        max_val =np.max(vflip)\n",
    "        vflip = 255 * ((vflip - min_val) / (max_val - min_val))\n",
    "        fvflip = vflip.astype(np.uint8)\n",
    "\n",
    "        nlmroi = nlmroi.astype(float)\n",
    "        min_val = np.min(nlmroi)\n",
    "        max_val =np.max(nlmroi)\n",
    "        nlmroi = 255 * ((nlmroi - min_val) / (max_val - min_val))\n",
    "        fnlmroi = nlmroi.astype(np.uint8)\n",
    "            \n",
    "        classif_size = (224, 224)\n",
    "        roi = cv2.resize(froi, classif_size, interpolation=cv2.INTER_LINEAR)\n",
    "        hflip = cv2.resize(fhflip, classif_size, interpolation=cv2.INTER_LINEAR)\n",
    "        vflip = cv2.resize(fvflip, classif_size, interpolation=cv2.INTER_LINEAR)\n",
    "        nlmroi = cv2.resize(fnlmroi, classif_size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        folder_name = class_assessment_to_folder.get((img_class, assessment), 'WRONG')\n",
    "        save_dir = os.path.join(preproc_dir, folder_name)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        file_roi = f\"{name}_{img_class}_o.png\"\n",
    "        file_roi_path = os.path.join(save_dir, file_roi)\n",
    "        \n",
    "        file_hflip = f\"{name}_{img_class}_h.png\"\n",
    "        file_hflip_path = os.path.join(save_dir, file_hflip)\n",
    "        \n",
    "        file_vflip = f\"{name}_{img_class}_v.png\"\n",
    "        file_vflip_path = os.path.join(save_dir, file_vflip)\n",
    "        \n",
    "        file_nlm = f\"{name}_{img_class}_nlm.png\"\n",
    "        file_nlm_path = os.path.join(save_dir, file_nlm)\n",
    "        \n",
    "        # GUARDAR\n",
    "        cv2.imwrite(file_roi_path, roi)\n",
    "        cv2.imwrite(file_hflip_path, hflip)\n",
    "        cv2.imwrite(file_vflip_path, vflip)\n",
    "        cv2.imwrite(file_nlm_path, nlmroi)\n",
    "        print (index)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation(file=\"../File.xlsx\", preproc_dir=\"../../Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On GPU version\n",
    "\n",
    "Don't forget switching to cupy_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize using CuPy\n",
    "def normalize(img):\n",
    "    img = cp.array(img, dtype=cp.float32)\n",
    "    min_val = cp.min(img)\n",
    "    max_val = cp.max(img)\n",
    "    img = 255 * ((img - min_val) / (max_val - min_val))\n",
    "    return cp.asnumpy(img.astype(cp.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_cuda(file, preproc_dir):\n",
    "    class_assessment_to_folder = {\n",
    "        ('Architectural distortion', 2): 'ArchDis_BR2',\n",
    "        ('Architectural distortion', 3): 'ArchDis_BR3',\n",
    "        ('Architectural distortion', 4): 'ArchDis_BR4',\n",
    "        ('Architectural distortion', 5): 'ArchDis_BR5',\n",
    "        ('Calcification', 2): 'Calcification_BR2',\n",
    "        ('Calcification', 3): 'Calcification_BR3',\n",
    "        ('Calcification', 4): 'Calcification_BR4',\n",
    "        ('Calcification', 5): 'Calcification_BR5',\n",
    "        ('Mass', 2): 'Mass_BR2',\n",
    "        ('Mass', 3): 'Mass_BR3',\n",
    "        ('Mass', 4): 'Mass_BR4',\n",
    "        ('Mass', 5): 'Mass_BR5',\n",
    "    }\n",
    "    \n",
    "    df = pd.read_excel(file)\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        assessment = row['birads']\n",
    "        name = row['CropFileName']\n",
    "        img_class = row['AbnormalityType']\n",
    "        image_path = row['imagePath']\n",
    "        index = round(row['Index'])\n",
    "        xmin = round(row['xmin'])\n",
    "        ymin = round(row['ymin'])\n",
    "        xmax = round(row['xmax'])\n",
    "        ymax = round(row['ymax'])\n",
    "        height = round(row['h'])\n",
    "        width = round(row['w'])\n",
    "        diff = abs(height - width)\n",
    "        \n",
    "        if image_path.endswith(('.dcm', '.dicom', '.DCM')): \n",
    "            image = dicom_to_3_channel(image_path)\n",
    "        elif image_path.endswith('.pgm'):\n",
    "            image = cv2.imread(image_path, -1)\n",
    "        else:\n",
    "            image = cv2.imread(image_path)\n",
    "        \n",
    "        if (xmin - (diff / 2)) >= 0 and (ymin - (diff / 2)) >= 0:\n",
    "            xmin, ymin, xmax, ymax = find_nxy(xmin, ymin, xmax, ymax, height, width, diff)\n",
    "            \n",
    "        roi = image[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "\n",
    "        if width != height:\n",
    "            roi = add_zeros(roi, height, width)\n",
    "        \n",
    "        roi_image = Image.fromarray(roi)\n",
    "\n",
    "        # Apply transformations\n",
    "        hflip = roi_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        vflip = roi_image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        hflip = np.array(hflip)\n",
    "        vflip = np.array(vflip)\n",
    "\n",
    "        nlmroi = nlm_filter(roi)\n",
    "        \n",
    "        roi = cp.array(roi)\n",
    "        hflip = cp.array(hflip)\n",
    "        vflip = cp.array(vflip)\n",
    "        nlmroi = cp.array(nlmroi)\n",
    "        \n",
    "        froi = normalize(roi)\n",
    "        fhflip = normalize(hflip)\n",
    "        fvflip = normalize(vflip)\n",
    "        fnlmroi = normalize(nlmroi)\n",
    "        \n",
    "        # Convert back to NumPy arrays for OpenCV operations\n",
    "        froi = cp.asnumpy(froi)\n",
    "        fhflip = cp.asnumpy(fhflip)\n",
    "        fvflip = cp.asnumpy(fvflip)\n",
    "        fnlmroi = cp.asnumpy(fnlmroi)\n",
    "\n",
    "        classif_size = (224, 224)\n",
    "        froi = cv2.resize(froi, classif_size, interpolation=cv2.INTER_LINEAR)\n",
    "        fhflip = cv2.resize(fhflip, classif_size, interpolation=cv2.INTER_LINEAR)\n",
    "        fvflip = cv2.resize(fvflip, classif_size, interpolation=cv2.INTER_LINEAR)\n",
    "        fnlmroi = cv2.resize(fnlmroi, classif_size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        folder_name = class_assessment_to_folder.get((img_class, assessment), 'WRONG')\n",
    "        save_dir = os.path.join(preproc_dir, folder_name)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        file_roi = f\"{name}_{img_class}_o.png\"\n",
    "        file_roi_path = os.path.join(save_dir, file_roi)\n",
    "        \n",
    "        file_hflip = f\"{name}_{img_class}_h.png\"\n",
    "        file_hflip_path = os.path.join(save_dir, file_hflip)\n",
    "        \n",
    "        file_vflip = f\"{name}_{img_class}_v.png\"\n",
    "        file_vflip_path = os.path.join(save_dir, file_vflip)\n",
    "        \n",
    "        file_nlm = f\"{name}_{img_class}_nlm.png\"\n",
    "        file_nlm_path = os.path.join(save_dir, file_nlm)\n",
    "        \n",
    "        # Save images\n",
    "        cv2.imwrite(file_roi_path, froi)\n",
    "        cv2.imwrite(file_hflip_path, fhflip)\n",
    "        cv2.imwrite(file_vflip_path, fvflip)\n",
    "        cv2.imwrite(file_nlm_path, fnlmroi)\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_cuda(file=\"./File.xlsx\", preproc_dir=\"././Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dl_folders(dataset, version):\n",
    "    dl_dirs = {\n",
    "        'train': os.path.join(version, 'train'),\n",
    "        'valid': os.path.join(version, 'valid'),\n",
    "        'test': os.path.join(version, 'test')\n",
    "    }\n",
    "    \n",
    "    # Create destination directories if they don't exist\n",
    "    for dl_dir in dl_dirs.values():\n",
    "        os.makedirs(dl_dir, exist_ok=True)\n",
    "        for subfolder in os.listdir(dataset):\n",
    "            os.makedirs(os.path.join(dl_dir, subfolder), exist_ok=True)\n",
    "    \n",
    "    train_ratio = 0.7\n",
    "    valid_ratio = 0.2\n",
    "    \n",
    "    for subfolder in os.listdir(dataset):\n",
    "        subfolder_path = os.path.join(dataset, subfolder)\n",
    "        \n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "        \n",
    "        images = [f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))]\n",
    "        \n",
    "        # Create a DataFrame for the current subfolder\n",
    "        df = pd.DataFrame(images, columns=['image'])\n",
    "        df['subfolder'] = subfolder\n",
    "        \n",
    "        # Shuffle the DataFrame\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        # Calculate the number of images for each category\n",
    "        total_images = len(df)\n",
    "        train_count = int(total_images * train_ratio)\n",
    "        valid_count = int(total_images * valid_ratio)\n",
    "        \n",
    "        df['category'] = ['train'] * train_count + \\\n",
    "                         ['valid'] * valid_count + \\\n",
    "                         ['test'] * (total_images - train_count - valid_count)\n",
    "        \n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        # Copy the images to the respective destination directories\n",
    "        for index, row in df.iterrows():\n",
    "            og_path = os.path.join(dataset, row['subfolder'], row['image'])\n",
    "            dest_path = os.path.join(dl_dirs[row['category']], row['subfolder'], row['image'])\n",
    "            shutil.copy(og_path, dest_path)\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dl_folders(dataset=\"C:/Users/sandra/Documents/Classifier_ResNet50/Calcification/Ver_23052024_PAUG/Dataset\", version=\"C:/Users/sandra/Documents/Classifier_ResNet50/Calcification/Ver_27052024_PAUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_ds(classif_root, output_root):\n",
    "    for dirpath, dirnames, filenames in os.walk(classif_root):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.png'):\n",
    "                # Get the subdirectory name\n",
    "                subdirectory_name = os.path.basename(dirpath)\n",
    "                \n",
    "                # Create a subfolder with the same name in the output directory\n",
    "                subfolder_path = os.path.join(output_root, subdirectory_name)\n",
    "                os.makedirs(subfolder_path, exist_ok=True)\n",
    "                \n",
    "                # Copy the .png file to the subfolder\n",
    "                src_path = os.path.join(dirpath, filename)\n",
    "                dst_path = os.path.join(subfolder_path, filename)\n",
    "                shutil.copy(src_path, dst_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
